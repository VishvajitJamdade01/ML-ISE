# Step 1: Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (classification_report, confusion_matrix, 
                             roc_curve, roc_auc_score, accuracy_score, 
                             precision_score, recall_score, f1_score)
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import StandardScaler, label_binarize
from sklearn.preprocessing import LabelEncoder
from sklearn.multiclass import OneVsRestClassifier

# Step 2: Load the dataset
data = pd.read_csv('/content/iris.csv')

print("Dataset Shape:", data.shape)
print("Columns:", data.columns.tolist())
print("Missing Values:\n", data.isnull().sum())

# Step 3: Encode target
le = LabelEncoder()
data['species_encoded'] = le.fit_transform(data['species'])

# Features and target
X = data.drop(columns=['species', 'species_encoded'])
y = data['species_encoded']

# Optional: Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 4: Feature selection
selector = SelectFromModel(RandomForestClassifier(random_state=42))
selector.fit(X_scaled, y)
selected_features = X.columns[selector.get_support()]
print("Selected Features:", list(selected_features))

X_selected = selector.transform(X_scaled)

# Step 5: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

# Step 6: Hyperparameter tuning
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'criterion': ['gini', 'entropy']
}

rf = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, 
                           cv=5, scoring='accuracy', verbose=1, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Step 7: Best model
best_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# Step 8: Predictions
y_pred = best_model.predict(X_test)
y_pred_proba = best_model.predict_proba(X_test)

# Step 9: Metrics (multi-class)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
roc_auc = roc_auc_score(label_binarize(y_test, classes=[0,1,2]),
                        y_pred_proba, average='macro', multi_class='ovr')

print("\nPerformance Metrics:")
print(f"Accuracy : {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall   : {recall:.2f}")
print(f"F1 Score : {f1:.2f}")
print(f"ROC AUC  : {roc_auc:.2f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Step 10: Confusion Matrix
conf_mat = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Step 11: ROC Curve (multi-class One-vs-Rest)
fpr = dict()
tpr = dict()
n_classes = len(le.classes_)
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])

plt.figure(figsize=(8, 6))
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])
    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc_score(y_test_bin[:, i], y_pred_proba[:, i]):.2f})')

plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multi-class ROC Curve (OvR)')
plt.legend()
plt.grid()
plt.show()
