# Step 1: Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import (classification_report, confusion_matrix, 
                             roc_curve, roc_auc_score, accuracy_score, 
                             precision_score, recall_score, f1_score)
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import LabelEncoder

# Step 2: Load the dataset
data = pd.read_csv('/content/iris.csv')

# Step 3: Preprocess the data
X = data.drop(columns=['species'])  # Features
y = data['species']  # Target

# Encode target to numeric for tree and ROC/AUC
le = LabelEncoder()
y_encoded = le.fit_transform(y)  # Converts classes to 0,1,2

# Step 4: Feature selection
selector_model = DecisionTreeClassifier(random_state=42)
selector = SelectFromModel(selector_model)
selector.fit(X, y_encoded)

selected_features = X.columns[selector.get_support()]
print("Selected Features:", list(selected_features))
X_selected = selector.transform(X)

# Step 5: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_selected, y_encoded, test_size=0.2, random_state=42)

# Step 6: Hyperparameter tuning
param_grid = {
    'max_depth': [None, 2, 4, 6, 8, 10],
    'min_samples_split': [2, 5, 10],
    'criterion': ['gini', 'log_loss']
}

dt_classifier = DecisionTreeClassifier(random_state=42)
grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, 
                           cv=5, scoring='accuracy', verbose=1, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Step 7: Results
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_
print("Best Parameters:", best_params)

# Step 8: Predictions
y_pred = best_model.predict(X_test)
y_pred_proba = best_model.predict_proba(X_test)

# Step 9: Evaluation Metrics (macro for multiclass)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')

print("\nPerformance Metrics:")
print(f"Accuracy : {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall   : {recall:.2f}")
print(f"F1 Score : {f1:.2f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Step 10: Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d',
            cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# Step 11: ROC Curve (multiclass)
# Binarize the output for ROC
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])
classifier_ovr = OneVsRestClassifier(best_model)
y_score = classifier_ovr.fit(X_train, y_train).predict_proba(X_test)

fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(3):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = roc_auc_score(y_test_bin[:, i], y_score[:, i])

# Plot all ROC curves
plt.figure(figsize=(8, 6))
colors = ['blue', 'green', 'orange']
for i, class_name in enumerate(le.classes_):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2,
             label=f'{class_name} (AUC = {roc_auc[i]:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multiclass ROC Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

# Step 12: Visualize Decision Tree
plt.figure(figsize=(12, 8))
plot_tree(best_model, feature_names=selected_features,
          class_names=le.classes_, filled=True, rounded=True,
          fontsize=10, node_ids=True, impurity=True)
plt.title("Optimized Decision Tree")
plt.show()
